services:
  # Proxy
  proxy: 
    profiles: ["dev"]
    image: haproxy:3.0-bookworm
    # entrypoint: ["/bin/sh", "-c", "sleep 1000"]
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./infrastructure/docker-compose/haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ${HOME}/ssl/my-app.pem:/etc/ssl/my-app.pem:ro

  # Backend
  web:
    profiles: ["prod", "dev"]
    image: aimeric/axum-demo:0.0.1
    # image: axum-demo
    # build: 
    #   dockerfile: Dockerfile.dev
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8080/health/live || exit 1
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 5s
    # ports:
    #   - 8080:8080
    environment:
      SERVICE_DB_HOST: db
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    volumes:
      - .:/app
    # tty: true
    # stdin_open: true
    depends_on:
      db:
        condition: service_healthy

  # Mandatory Services
  db:
    profiles: ["dev", "prod"]
    image: postgres:15
    user: postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 5s
      timeout: 5s
      retries: 10
    # ports:
    #   - 5432:5432
    environment:
      POSTGRES_PASSWORD: "welcome"
      POSTGRES_DB: "app_db"
    volumes:
      - ./infrastructure/docker-compose/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro

  # Telemetry Components
  otel-collector:
    profiles: ["dev", "prod"]
    image: otel/opentelemetry-collector-contrib:0.119.0
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:13133 || exit 1
    volumes:
      - ./infrastructure/docker-compose/otel/otel-collector.yaml:/etc/otelcol-contrib/config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro # Monitor Docker metrics
      # - /proc:/hostfs/proc # Monitor System metrics (Linux Only)
    # ports:
    #   - 4317:4317 # OTLP gRPC receiver
    #   - 8888:8888 # Prometheus metrics exposed by the collector
    #   - 13133:13133 # health_check extension
    #   - 55679:55679 # zpages
    environment:
      GRAFANA_CLOUD_OTLP_ENDPOINT: ${GRAFANA_CLOUD_OTLP_ENDPOINT:-default}
      GRAFANA_CLOUD_INSTANCE_ID: ${GRAFANA_CLOUD_INSTANCE_ID:-default}
      GRAFANA_CLOUD_API_KEY: ${GRAFANA_CLOUD_API_KEY:-default}

  # Ports used : 1234, 9090
  prometheus:
    profiles: ["dev", "prod"]
    image: prom/prometheus:v3.1.0
    command:
      - --web.enable-otlp-receiver
      - --web.enable-remote-write-receiver
      - --config.file=/etc/prometheus/prometheus.yml
      - --enable-feature=native-histograms
      - --web.external-url=/prometheus/
    volumes:
      - ./infrastructure/docker-compose/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro

  # Ports used : 16686, 4317
  jaeger:
    profiles: ["dev", "prod"]
    image: jaegertracing/all-in-one:1.66.0
    environment:
      QUERY_BASE_PATH: "/my-app/jaeger"

  # Port used : 3000
  grafana:
    profiles: ["dev", "prod"]
    image: grafana/grafana:11.5.1
    
    environment:
      GF_USERS_DEFAULT_THEME: "light"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Admin"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_BASIC_ENABLED: "false"
      GF_SERVER_ROOT_URL: "https://my-app/grafana"
    volumes:
      - ./infrastructure/docker-compose/grafana:/etc/grafana/provisioning:ro

  # Tests
  k6:
    profiles: ["test"]
    image: grafana/k6:0.57.0
    volumes:
      - ./infrastructure/docker-compose/k6:/home/k6
    user:
      root
    entrypoint: ["/bin/sh", "-c"]
    command: ["k6 run ${K6_FILE:-script.js}"]
    environment:
      K6_PROMETHEUS_RW_SERVER_URL: "http://prometheus:9090/api/v1/write"
      K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM: "true"
      K6_FILE: ${K6_FILE:-script.js}
